{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00_dim_riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SILVER_TABLE = \"divvy.dim_riders\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_TABLE};\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = spark.table(\"divvy.bronze_riders\")\n",
    "\n",
    "df = df.withColumn(\"ride_id\", df.rider_id.cast(\"int\"))\n",
    "df = df.withColumn(\"birthday\", df.birthday.cast(\"date\"))\n",
    "df = df.withColumn(\"account_start_date\", df.account_start_date.cast(\"date\"))\n",
    "df = df.withColumn(\"account_end_date\", df.account_end_date.cast(\"date\"))\n",
    "df = df.withColumn(\"is_member\", df.is_member.cast(\"boolean\"))\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_dim_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SILVER_TABLE = \"divvy.dim_stations\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_TABLE};\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = spark.table(\"divvy.bronze_stations\")\n",
    "\n",
    "df = df.withColumn(\"latitute\", df.latitute.cast(\"float\"))\n",
    "df = df.withColumn(\"longitude\", df.longitude.cast(\"float\"))\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, sequence, to_date\n",
    "\n",
    "SILVER_TABLE_NAME = \"divvy.dim_date\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_TABLE_NAME};\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "beginDate = \"2015-01-01\"\n",
    "endDate = \"2030-12-31\"\n",
    "\n",
    "spark.sql(\n",
    "    f\"select explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as date\"\n",
    ").createOrReplaceTempView(\"dates\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "create or replace table divvy.dim_date\n",
    "using delta\n",
    "as select\n",
    "  year(date) * 10000 + month(date) * 100 + day(date) as date_int,\n",
    "  date,\n",
    "  year(date) AS year,\n",
    "  date_format(date, 'MMMM') as calendar_month,\n",
    "  month(date) as month,\n",
    "  date_format(date, 'EEEE') as calendar_day,\n",
    "  dayofweek(date) as day_of_week,\n",
    "  weekday(date) + 1 as day_of_week_start_monday,\n",
    "  case\n",
    "    when weekday(date) < 5 then 'Y'\n",
    "    else 'N'\n",
    "  end as is_week_day,\n",
    "  dayofmonth(date) as day_of_month,\n",
    "  case\n",
    "    when date = last_day(date) then 'Y'\n",
    "    else 'N'\n",
    "  end as is_last_day_of_month,\n",
    "  dayofyear(date) as day_of_year,\n",
    "  weekofyear(date) as week_of_year_iso,\n",
    "  quarter(date) as quarter_of_year\n",
    "from\n",
    "  dates\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(\"optimize divvy.dim_date zorder by (date)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03_fact_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "from pyspark.sql.functions import months_between, col\n",
    "\n",
    "SILVER_TABLE = \"divvy.fact_trips\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_TABLE};\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "riders_df = spark.table(\"divvy.dim_riders\").select(\n",
    "    col(\"rider_id\").alias(\"rider_rider_id\"),\n",
    "    col(\"birthday\"),\n",
    ")\n",
    "trips_df = spark.table(\"divvy.bronze_trips\")\n",
    "\n",
    "trips_df = trips_df.withColumn(\"start_at\", trips_df.start_at.cast(\"timestamp\"))\n",
    "trips_df = trips_df.withColumn(\"ended_at\", trips_df.ended_at.cast(\"timestamp\"))\n",
    "trips_df = trips_df.withColumn(\"start_at_date\", trips_df.start_at.cast(\"date\"))\n",
    "trips_df = trips_df.withColumn(\"ended_at_date\", trips_df.ended_at.cast(\"date\"))\n",
    "trips_df = trips_df.withColumn(\"rider_id\", trips_df.rider_id.cast(\"int\"))\n",
    "trips_df = trips_df.withColumn(\n",
    "    \"time_spent\", trips_df.ended_at.cast(\"long\") - trips_df.start_at.cast(\"long\")\n",
    ")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "joined_df = trips_df.join(\n",
    "    riders_df, trips_df.rider_id == riders_df.rider_rider_id, \"inner\"\n",
    ")\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"rider_age_at_time\",\n",
    "    (months_between(trips_df.start_at, joined_df.birthday) / 12).cast(\"int\"),\n",
    ")\n",
    "joined_df.drop(\n",
    "    \"rider_rider_id\",\n",
    ")\n",
    "\n",
    "joined_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_fact_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import months_between, col\n",
    "\n",
    "SILVER_TABLE = \"divvy.fact_payments\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_TABLE};\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "riders_df = spark.table(\"divvy.dim_riders\").select(\n",
    "    col(\"rider_id\").alias(\"rider_rider_id\"), col(\"birthday\"), col(\"account_start_date\")\n",
    ")\n",
    "payments_df = spark.table(\"divvy.bronze_payments\")\n",
    "\n",
    "payments_df = payments_df.withColumn(\"payment_id\", payments_df.payment_id.cast(\"int\"))\n",
    "payments_df = payments_df.withColumn(\"date\", payments_df.date.cast(\"date\"))\n",
    "payments_df = payments_df.withColumn(\"amount\", payments_df.amount.cast(\"decimal\"))\n",
    "payments_df = payments_df.withColumn(\"rider_id\", payments_df.rider_id.cast(\"int\"))\n",
    "\n",
    "joined_df = payments_df.join(\n",
    "    riders_df, payments_df.rider_id == riders_df.rider_rider_id, \"inner\"\n",
    ")\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"rider_age_account_start\",\n",
    "    (months_between(joined_df.account_start_date, joined_df.birthday) / 12).cast(\"int\"),\n",
    ")\n",
    "joined_df.drop(\"rider_rider_id\", \"birthday\", \"account_start_date\")\n",
    "\n",
    "joined_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_TABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
