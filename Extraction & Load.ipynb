{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze - Extaction & Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b289475d-3b0f-4a7d-8bf2-ecaffffe0111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS divvy\")\n",
    "BRONZE_TABLE = \"divvy.bronze_payments\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BRONZE_TABLE};\")\n",
    "df = (\n",
    "    spark.read.format(\"csv\").option(\"sep\", \",\").load(\"/FileStore/tables/payments.csv\")\n",
    ")\n",
    "df = df.withColumn(\"payment_id\", df._c0)\n",
    "df = df.withColumn(\"date\", df._c1)\n",
    "df = df.withColumn(\"amount\", df._c2)\n",
    "df = df.withColumn(\"rider_id\", df._c3)\n",
    "column_to_drop = [\"_c0\", \"_c1\", \"_c2\", \"_c3\"]\n",
    "df = df.drop(*column_to_drop)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ebf378-bda7-48ec-9fb8-acf984ac68a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bronze import *\n",
    "\n",
    "BRONZE_TABLE = \"divvy.bronze_riders\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BRONZE_TABLE};\")\n",
    "df = spark.read.format(\"csv\").option(\"sep\", \",\").load(\"/FileStore/tables/riders.csv\")\n",
    "\n",
    "df = df.withColumn(\"rider_id\", df._c0)\n",
    "df = df.withColumn(\"first\", df._c1)\n",
    "df = df.withColumn(\"last\", df._c2)\n",
    "df = df.withColumn(\"address\", df._c3)\n",
    "df = df.withColumn(\"birthday\", df._c4)\n",
    "df = df.withColumn(\"account_start_date\", df._c5)\n",
    "df = df.withColumn(\"account_end_date\", df._c6)\n",
    "df = df.withColumn(\"is_member\", df._c7)\n",
    "\n",
    "\n",
    "columns_to_drop = [\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\", \"_c7\"]\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BRONZE_TABLE = \"divvy.bronze_stations\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BRONZE_TABLE};\")\n",
    "df = (\n",
    "    spark.read.format(\"csv\").option(\"sep\", \",\").load(\"/FileStore/tables/stations.csv\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"station_id\", df._c0)\n",
    "df = df.withColumn(\"name\", df._c1)\n",
    "df = df.withColumn(\"latitute\", df._c2.cast(\"float\"))\n",
    "df = df.withColumn(\"longitude\", df._c3.cast(\"float\"))\n",
    "\n",
    "columns_to_drop = [\"_c0\", \"_c1\", \"_c2\", \"_c3\"]\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e39f572-6a0e-460a-9dcc-eb6b2e615a59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BRONZE_TABLE = \"divvy.bronze_trips\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BRONZE_TABLE};\")\n",
    "df = spark.read.format(\"csv\").option(\"sep\", \",\").load(\"/FileStore/tables/trips.csv\")\n",
    "\n",
    "df = df.withColumn(\"trip_id\", df._c0)\n",
    "df = df.withColumn(\"rideable_type\", df._c1)\n",
    "df = df.withColumn(\"start_at\", df._c2)\n",
    "df = df.withColumn(\"ended_at\", df._c3)\n",
    "\n",
    "df = df.withColumn(\"start_station_id\", df._c4)\n",
    "df = df.withColumn(\"end_station_id\", df._c5)\n",
    "df = df.withColumn(\"rider_id\", df._c6)\n",
    "\n",
    "columns_to_drop = [\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\"]\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_TABLE)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_payments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
