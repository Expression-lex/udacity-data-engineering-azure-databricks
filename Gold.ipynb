{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_trips_time_per_membertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "from gold import *\n",
    "\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_trips_time_per_membertype\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_trips\")\n",
    "rider_df = spark.table(\"divvy.dim_riders\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = df.join(rider_df, df.rider_id == rider_df.rider_id, \"inner\")\n",
    "df = (\n",
    "    df.groupby(df.is_member)\n",
    "    .agg(\n",
    "        F.avg(df.time_spent).alias(\"avg_time_spent\"),\n",
    "        F.sum(df.time_spent).alias(\"sum_time_spent\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"is_member\"),\n",
    "        F.col(\"avg_time_spent\"),\n",
    "        F.col(\"sum_time_spent\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_trips_time_per_membertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_trips_time_per_stations\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_trips\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.start_station_id, df.end_station_id)\n",
    "    .agg(\n",
    "        F.avg(df.time_spent).alias(\"avg_time_spent\"),\n",
    "        F.sum(df.time_spent).alias(\"sum_time_spent\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"start_station_id\"),\n",
    "        F.col(\"end_station_id\"),\n",
    "        F.col(\"avg_time_spent\"),\n",
    "        F.col(\"sum_time_spent\"),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03_payments_per_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_payments_per_date\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_payments\")\n",
    "date_df = spark.table(\"divvy.dim_date\")\n",
    "\n",
    "df = df.join(date_df, df.date == date_df.date, \"inner\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.year, df.quarter_of_year, df.month)\n",
    "    .agg(\n",
    "        F.avg(df.amount).alias(\"avg_amount\"),\n",
    "        F.sum(df.amount).alias(\"sum_amount\"),\n",
    "    )\n",
    "    .orderBy(\"year\", \"quarter_of_year\", \"month\")\n",
    "    .select(\n",
    "        F.col(\"year\"),\n",
    "        F.col(\"quarter_of_year\"),\n",
    "        F.col(\"month\"),\n",
    "        F.col(\"avg_amount\"),\n",
    "        F.col(\"sum_amount\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_payments_per_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_payments_per_age\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_payments\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.rider_age_account_start)\n",
    "    .agg(\n",
    "        F.avg(df.amount).alias(\"avg_amount\"),\n",
    "        F.sum(df.amount).alias(\"sum_amount\"),\n",
    "    )\n",
    "    .orderBy(df.rider_age_account_start)\n",
    "    .select(\n",
    "        F.col(\"rider_age_account_start\"),\n",
    "        F.col(\"avg_amount\"),\n",
    "        F.col(\"sum_amount\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05_trips_per_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_trips_per_date\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_trips\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "date_df = spark.table(\"divvy.dim_date\")\n",
    "\n",
    "df = df.join(date_df, df.start_at_date == date_df.date, \"inner\")\n",
    "df = df.withColumn(\"time_15_min\", F.floor(F.minute(df.start_at) / 15) + 1)\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.day_of_week, df.time_15_min)\n",
    "    .agg(\n",
    "        F.avg(df.time_spent).alias(\"avg_time_spent\"),\n",
    "        F.sum(df.time_spent).alias(\"sum_time_spent\"),\n",
    "    )\n",
    "    .orderBy(df.day_of_week, df.time_15_min)\n",
    "    .select(\n",
    "        F.col(\"day_of_week\"),\n",
    "        F.col(\"time_15_min\"),\n",
    "        F.col(\"avg_time_spent\"),\n",
    "        F.col(\"sum_time_spent\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06_payments_per_rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_payments_per_rides\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_payments\")\n",
    "date_df = spark.table(\"divvy.dim_date\").select(\n",
    "    F.col(\"date\"),\n",
    "    F.col(\"month\"),\n",
    ")\n",
    "df = df.join(date_df, df.date == date_df.date, \"inner\")\n",
    "\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.rider_id, df.month)\n",
    "    .agg(\n",
    "        F.count(df.rider_id).alias(\"count_rides\"),\n",
    "        F.avg(df.amount).alias(\"avg_amount\"),\n",
    "        F.sum(df.amount).alias(\"sum_amount\"),\n",
    "    )\n",
    "    .orderBy(\"rider_id\", \"month\")\n",
    "    .select(\n",
    "        F.col(\"rider_id\"),\n",
    "        F.col(\"month\"),\n",
    "        F.col(\"avg_amount\"),\n",
    "        F.col(\"sum_amount\"),\n",
    "        F.col(\"count_rides\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07_payments_per_rides_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gold import *\n",
    "\n",
    "GOLD_TABLE = \"divvy.gold_payments_per_rides_minutes\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE};\")\n",
    "\n",
    "df = spark.table(\"divvy.fact_payments\")\n",
    "date_df = spark.table(\"divvy.dim_date\").select(\n",
    "    F.col(\"date\"),\n",
    "    F.col(\"month\"),\n",
    "    F.col(\"year\"),\n",
    ")\n",
    "df = df.join(date_df, df.date == date_df.date, \"inner\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Refactored code\n",
    "trips_df = spark.table(\"divvy.fact_trips\")\n",
    "trips_df = trips_df.join(date_df, trips_df.start_at_date == date_df.date, \"inner\")\n",
    "trips_df = (\n",
    "    trips_df.groupby(trips_df.rider_id, trips_df.month, trips_df.year)\n",
    "    .agg(\n",
    "        F.sum(trips_df.time_spent).alias(\"sum_time_spent\"),\n",
    "    )\n",
    "    .selectExpr(\"rider_id AS trips_rider_id\", \"month AS trips_month\", \"year AS trips_year\", \"sum_time_spent\")\n",
    "    .orderBy(\"rider_id\", \"year\", \"month\")\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = (\n",
    "    df.groupby(df.rider_id, df.month, df.year)\n",
    "    .agg(\n",
    "        F.sum(df.amount).alias(\"sum_amount\"),\n",
    "    )\n",
    "    .orderBy(\"rider_id\", \"year\", \"month\")\n",
    "    .select(\n",
    "        F.col(\"rider_id\"),\n",
    "        F.col(\"month\"),\n",
    "        F.col(\"year\"),\n",
    "        F.col(\"sum_amount\"),\n",
    "    )\n",
    ")\n",
    "conds = [\n",
    "    df.rider_id == trips_df.trips_rider_id,\n",
    "    df.month == trips_df.trips_month,\n",
    "    df.year == trips_df.trips_year,\n",
    "]\n",
    "df = df.join(trips_df, conds, \"inner\").select(\n",
    "    F.col(\"rider_id\"),\n",
    "    F.col(\"month\"),\n",
    "    F.col(\"year\"),\n",
    "    F.col(\"sum_amount\"),\n",
    "    F.col(\"sum_time_spent\"),\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
